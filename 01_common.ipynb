{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inpaint_melanoma\n",
    "\n",
    "> Inpaint a skin lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_module(self, module):\n",
    "    self.add_module(str(len(self) + 1), module)\n",
    "    \n",
    "torch.nn.Module.add = add_module\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dim, *args):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, input):\n",
    "        inputs = []\n",
    "        for module in self._modules.values():\n",
    "            inputs.append(module(input))\n",
    "\n",
    "        inputs_shapes2 = [x.shape[2] for x in inputs]\n",
    "        inputs_shapes3 = [x.shape[3] for x in inputs]        \n",
    "\n",
    "        if np.all(np.array(inputs_shapes2) == min(inputs_shapes2)) and np.all(np.array(inputs_shapes3) == min(inputs_shapes3)):\n",
    "            inputs_ = inputs\n",
    "        else:\n",
    "            target_shape2 = min(inputs_shapes2)\n",
    "            target_shape3 = min(inputs_shapes3)\n",
    "\n",
    "            inputs_ = []\n",
    "            for inp in inputs: \n",
    "                diff2 = (inp.size(2) - target_shape2) // 2 \n",
    "                diff3 = (inp.size(3) - target_shape3) // 2 \n",
    "                inputs_.append(inp[:, :, diff2: diff2 + target_shape2, diff3:diff3 + target_shape3])\n",
    "\n",
    "        return torch.cat(inputs_, dim=self.dim)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class GenNoise(nn.Module):\n",
    "    def __init__(self, dim2):\n",
    "        super(GenNoise, self).__init__()\n",
    "        self.dim2 = dim2\n",
    "\n",
    "    def forward(self, input):\n",
    "        a = list(input.size())\n",
    "        a[1] = self.dim2\n",
    "        # print (input.data.type())\n",
    "\n",
    "        b = torch.zeros(a).type_as(input.data)\n",
    "        b.normal_()\n",
    "\n",
    "        x = torch.autograd.Variable(b)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "        https://arxiv.org/abs/1710.05941\n",
    "        The hype was so huge that I could not help but try it\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "        self.s = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.s(x)\n",
    "\n",
    "\n",
    "def act(act_fun = 'LeakyReLU'):\n",
    "    '''\n",
    "        Either string defining an activation function or module (e.g. nn.ReLU)\n",
    "    '''\n",
    "    if isinstance(act_fun, str):\n",
    "        if act_fun == 'LeakyReLU':\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act_fun == 'Swish':\n",
    "            return Swish()\n",
    "        elif act_fun == 'ELU':\n",
    "            return nn.ELU()\n",
    "        elif act_fun == 'none':\n",
    "            return nn.Sequential()\n",
    "        else:\n",
    "            assert False\n",
    "    else:\n",
    "        return act_fun()\n",
    "\n",
    "\n",
    "def bn(num_features):\n",
    "    return nn.BatchNorm2d(num_features)\n",
    "\n",
    "\n",
    "def conv(in_f, out_f, kernel_size, stride=1, bias=True, pad='zero', downsample_mode='stride'):\n",
    "    downsampler = None\n",
    "    if stride != 1 and downsample_mode != 'stride':\n",
    "\n",
    "        if downsample_mode == 'avg':\n",
    "            downsampler = nn.AvgPool2d(stride, stride)\n",
    "        elif downsample_mode == 'max':\n",
    "            downsampler = nn.MaxPool2d(stride, stride)\n",
    "        elif downsample_mode  in ['lanczos2', 'lanczos3']:\n",
    "            downsampler = Downsampler(n_planes=out_f, factor=stride, kernel_type=downsample_mode, phase=0.5, preserve_size=True)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        stride = 1\n",
    "\n",
    "    padder = None\n",
    "    to_pad = int((kernel_size - 1) / 2)\n",
    "    if pad == 'reflection':\n",
    "        padder = nn.ReflectionPad2d(to_pad)\n",
    "        to_pad = 0\n",
    "  \n",
    "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
    "    torch.nn.init.xavier_uniform_(convolver.weight) # Added by OMM (Xavier init)\n",
    "\n",
    "    layers = filter(lambda x: x is not None, [padder, convolver, downsampler])\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Downsampler(nn.Module):\n",
    "    '''\n",
    "        http://www.realitypixels.com/turk/computergraphics/ResamplingFilters.pdf\n",
    "    '''\n",
    "    def __init__(self, n_planes, factor, kernel_type, phase=0, kernel_width=None, support=None, sigma=None, preserve_size=False):\n",
    "        super(Downsampler, self).__init__()\n",
    "        \n",
    "        assert phase in [0, 0.5], 'phase should be 0 or 0.5'\n",
    "\n",
    "        if kernel_type == 'lanczos2':\n",
    "            support = 2\n",
    "            kernel_width = 4 * factor + 1\n",
    "            kernel_type_ = 'lanczos'\n",
    "\n",
    "        elif kernel_type == 'lanczos3':\n",
    "            support = 3\n",
    "            kernel_width = 6 * factor + 1\n",
    "            kernel_type_ = 'lanczos'\n",
    "\n",
    "        elif kernel_type == 'gauss12':\n",
    "            kernel_width = 7\n",
    "            sigma = 1/2\n",
    "            kernel_type_ = 'gauss'\n",
    "\n",
    "        elif kernel_type == 'gauss1sq2':\n",
    "            kernel_width = 9\n",
    "            sigma = 1./np.sqrt(2)\n",
    "            kernel_type_ = 'gauss'\n",
    "\n",
    "        elif kernel_type in ['lanczos', 'gauss', 'box']:\n",
    "            kernel_type_ = kernel_type\n",
    "\n",
    "        else:\n",
    "            assert False, 'wrong name kernel'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
