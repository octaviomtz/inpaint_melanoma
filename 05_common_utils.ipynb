{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp common_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inpaint_melanoma\n",
    "\n",
    "> Inpaint a skin lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crop_image(img, d=32):\n",
    "    '''Make dimensions divisible by `d`'''\n",
    "\n",
    "    new_size = (img.size[0] - img.size[0] % d, \n",
    "                img.size[1] - img.size[1] % d)\n",
    "\n",
    "    bbox = [\n",
    "            int((img.size[0] - new_size[0])/2), \n",
    "            int((img.size[1] - new_size[1])/2),\n",
    "            int((img.size[0] + new_size[0])/2),\n",
    "            int((img.size[1] + new_size[1])/2),\n",
    "    ]\n",
    "\n",
    "    img_cropped = img.crop(bbox)\n",
    "    return img_cropped\n",
    "\n",
    "def get_params(opt_over, net, net_input, downsampler=None):\n",
    "    '''Returns parameters that we want to optimize over.\n",
    "    Args:\n",
    "        opt_over: comma separated list, e.g. \"net,input\" or \"net\"\n",
    "        net: network\n",
    "        net_input: torch.Tensor that stores input `z`\n",
    "    '''\n",
    "    opt_over_list = opt_over.split(',')\n",
    "    params = []\n",
    "    \n",
    "    for opt in opt_over_list:\n",
    "    \n",
    "        if opt == 'net':\n",
    "            params += [x for x in net.parameters() ]\n",
    "        elif  opt=='down':\n",
    "            assert downsampler is not None\n",
    "            params = [x for x in downsampler.parameters()]\n",
    "        elif opt == 'input':\n",
    "            net_input.requires_grad = True\n",
    "            params += [net_input]\n",
    "        else:\n",
    "            assert False, 'what is it?'\n",
    "            \n",
    "    return params\n",
    "\n",
    "def get_image_grid(images_np, nrow=8):\n",
    "    '''Creates a grid from a list of images by concatenating them.'''\n",
    "    images_torch = [(torch.from_numpy(x)).double() for x in images_np] # OMM added ().double()\n",
    "    torch_grid = torchvision.utils.make_grid(images_torch, nrow)\n",
    "    \n",
    "    return torch_grid.numpy()\n",
    "\n",
    "def plot_image_grid(images_np, nrow =8, factor=1, interpolation=None): # OMM 'lanczos' -> None\n",
    "    \"\"\"Draws images in a grid\n",
    "    \n",
    "    Args:\n",
    "        images_np: list of images, each image is np.array of size 3xHxW of 1xHxW\n",
    "        nrow: how many images will be in one row\n",
    "        factor: size if the plt.figure \n",
    "        interpolation: interpolation used in plt.imshow\n",
    "    \"\"\"\n",
    "    n_channels = max(x.shape[0] for x in images_np)\n",
    "    assert (n_channels == 3) or (n_channels == 1), \"images should have 1 or 3 channels\"\n",
    "    \n",
    "    images_np = [x if (x.shape[0] == n_channels) else np.concatenate([x, x, x], axis=0) for x in images_np]\n",
    "\n",
    "    grid = get_image_grid(images_np, nrow)\n",
    "    \n",
    "    plt.figure(figsize=(len(images_np) + factor, 12 + factor))\n",
    "    \n",
    "    if images_np[0].shape[0] == 1:\n",
    "        plt.imshow(grid[0], cmap='viridis', interpolation=interpolation) #OMM 'gray' -> 'viridis'\n",
    "    else:\n",
    "        plt.imshow(grid.transpose(1, 2, 0), interpolation=interpolation)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def load(path):\n",
    "    \"\"\"Load PIL image.\"\"\"\n",
    "    img = Image.open(path)\n",
    "    return img\n",
    "\n",
    "def get_image(path, imsize=-1):\n",
    "    \"\"\"Load an image and resize to a cpecific size. \n",
    "    Args: \n",
    "        path: path to image\n",
    "        imsize: tuple or scalar with dimensions; -1 for `no resize`\n",
    "    \"\"\"\n",
    "    img = load(path)\n",
    "\n",
    "    if isinstance(imsize, int):\n",
    "        imsize = (imsize, imsize)\n",
    "\n",
    "    if imsize[0]!= -1 and img.size != imsize:\n",
    "        if imsize[0] > img.size[0]:\n",
    "            img = img.resize(imsize, Image.BICUBIC)\n",
    "        else:\n",
    "            img = img.resize(imsize, Image.ANTIALIAS)\n",
    "\n",
    "    img_np = pil_to_np(img)\n",
    "\n",
    "    return img, img_np\n",
    "\n",
    "\n",
    "\n",
    "def fill_noise(x, noise_type):\n",
    "    \"\"\"Fills tensor `x` with noise of type `noise_type`.\"\"\"\n",
    "    if noise_type == 'u':\n",
    "        x.uniform_()\n",
    "    elif noise_type == 'n':\n",
    "        x.normal_() \n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "def get_noise(input_depth, method, spatial_size, noise_type='u', var=1./10):\n",
    "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`) \n",
    "    initialized in a specific way.\n",
    "    Args:\n",
    "        input_depth: number of channels in the tensor\n",
    "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
    "        spatial_size: spatial size of the tensor to initialize\n",
    "        noise_type: 'u' for uniform; 'n' for normal\n",
    "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler. \n",
    "    \"\"\"\n",
    "    if isinstance(spatial_size, int):\n",
    "        spatial_size = (spatial_size, spatial_size)\n",
    "    if method == 'noise':\n",
    "        shape = [1, input_depth, spatial_size[0], spatial_size[1]]\n",
    "        net_input = torch.zeros(shape)\n",
    "        \n",
    "        fill_noise(net_input, noise_type)\n",
    "        net_input *= var            \n",
    "    elif method == 'meshgrid': \n",
    "        assert input_depth == 2\n",
    "        X, Y = np.meshgrid(np.arange(0, spatial_size[1])/float(spatial_size[1]-1), np.arange(0, spatial_size[0])/float(spatial_size[0]-1))\n",
    "        meshgrid = np.concatenate([X[None,:], Y[None,:]])\n",
    "        net_input=  np_to_torch(meshgrid)\n",
    "    else:\n",
    "        assert False\n",
    "        \n",
    "    return net_input\n",
    "\n",
    "def get_noise2(input_depth, method, spatial_size, noise_type='u', var=1./10):\n",
    "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`)\n",
    "    initialized in a specific way.\n",
    "    Args:\n",
    "        input_depth: number of channels in the tensor\n",
    "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
    "        spatial_size: spatial size of the tensor to initialize\n",
    "        noise_type: 'u' for uniform; 'n' for normal\n",
    "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler.\n",
    "    \"\"\"\n",
    "    if isinstance(spatial_size, int):\n",
    "        spatial_size = (spatial_size, spatial_size)\n",
    "    if method == 'noise':\n",
    "        shape = [1, input_depth, spatial_size[0], spatial_size[1]]\n",
    "        net_input = torch.zeros(shape)\n",
    "\n",
    "        fill_noise(net_input, noise_type)\n",
    "        net_input *= var\n",
    "        #net_input += .7 #WARNING ADDED FOR MELANOMA\n",
    "        print('using get_noise2')\n",
    "    elif method == 'meshgrid':\n",
    "        assert input_depth == 2\n",
    "        X, Y = np.meshgrid(np.arange(0, spatial_size[1])/float(spatial_size[1]-1), np.arange(0, spatial_size[0])/float(spatial_size[0]-1))\n",
    "        meshgrid = np.concatenate([X[None,:], Y[None,:]])\n",
    "        net_input=  np_to_torch(meshgrid)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    return net_input\n",
    "\n",
    "\n",
    "def pil_to_np(img_PIL):\n",
    "    '''Converts image in PIL format to np.array.\n",
    "    \n",
    "    From W x H x C [0...255] to C x W x H [0..1]\n",
    "    '''\n",
    "    ar = np.array(img_PIL)\n",
    "\n",
    "    if len(ar.shape) == 3:\n",
    "        ar = ar.transpose(2,0,1)\n",
    "    else:\n",
    "        ar = ar[None, ...]\n",
    "\n",
    "    return ar.astype(np.float32) / 255.\n",
    "\n",
    "def np_to_pil(img_np): \n",
    "    '''Converts image in np.array format to PIL image.\n",
    "    \n",
    "    From C x W x H [0..1] to  W x H x C [0...255]\n",
    "    '''\n",
    "    ar = np.clip(img_np*255,0,255).astype(np.uint8)\n",
    "    \n",
    "    if img_np.shape[0] == 1:\n",
    "        ar = ar[0]\n",
    "    else:\n",
    "        ar = ar.transpose(1, 2, 0)\n",
    "\n",
    "    return Image.fromarray(ar)\n",
    "\n",
    "def np_to_torch(img_np):\n",
    "    '''Converts image in numpy.array to torch.Tensor.\n",
    "    From C x W x H [0..1] to  C x W x H [0..1]\n",
    "    '''\n",
    "    return torch.from_numpy(img_np)[None, :]\n",
    "\n",
    "def torch_to_np(img_var):\n",
    "    '''Converts an image in torch.Tensor format to np.array.\n",
    "    From 1 x C x W x H [0..1] to  C x W x H [0..1]\n",
    "    '''\n",
    "    return img_var.detach().cpu().numpy()[0]\n",
    "\n",
    "\n",
    "def optimize(optimizer_type, parameters, closure, LR, num_iter, show_every):\n",
    "    \"\"\"Runs optimization loop.\n",
    "    Args:\n",
    "        optimizer_type: 'LBFGS' of 'adam'\n",
    "        parameters: list of Tensors to optimize over\n",
    "        closure: function, that returns loss variable\n",
    "        LR: learning rate\n",
    "        num_iter: number of iterations \n",
    "    \"\"\"\n",
    "    total_loss = []\n",
    "    images_generated = []\n",
    "    if optimizer_type == 'LBFGS':\n",
    "        # Do several steps with adam first\n",
    "        optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "        for j in range(100):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Starting optimization with LBFGS')        \n",
    "        def closure2():\n",
    "            optimizer.zero_grad()\n",
    "            return closure()\n",
    "        optimizer = torch.optim.LBFGS(parameters, max_iter=num_iter, lr=LR, tolerance_grad=-1, tolerance_change=-1)\n",
    "        optimizer.step(closure2)\n",
    "\n",
    "    elif optimizer_type == 'adam':\n",
    "        print('Starting optimization with ADAM')\n",
    "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "        \n",
    "        for j in range(num_iter):\n",
    "            #if j ==0: DEL \n",
    "                #loss_best=1000 #DEL\n",
    "            optimizer.zero_grad()\n",
    "            total_loss_temp, image_generated_temp = closure()\n",
    "            total_loss.append(total_loss_temp)\n",
    "            #if j < 50 and j % 10 == 0:\n",
    "                #images_generated.append(image_generated_temp)\n",
    "            if j % show_every == 0:\n",
    "            #if total_loss_temp < loss_best:\n",
    "                #loss_best = total_loss_temp\n",
    "                images_generated.append(image_generated_temp)\n",
    "            #print(f'total_loss_temp:{total_loss_temp}')\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        assert False\n",
    "    return total_loss, images_generated\n",
    "\n",
    "def plot_for_gif(image_to_save,num_iter, i, path_img_dest):\n",
    "    fig, ax = plt.subplots(1,2, gridspec_kw = {'width_ratios':[8, 1]}, figsize=(14,10))\n",
    "    ax[0].imshow(image_to_save[0], cmap='viridis')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axvline(x=.5, c='k')\n",
    "    ax[1].scatter(.5, i, c='k')\n",
    "    ax[1].set_ylim([num_iter, 0])\n",
    "    ax[1].yaxis.tick_right()\n",
    "    ax[1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    # ax[1].xticks([], [])\n",
    "    ax[1].spines[\"top\"].set_visible(False)\n",
    "    ax[1].spines[\"bottom\"].set_visible(False)\n",
    "    ax[1].spines[\"left\"].set_visible(False)\n",
    "    ax[1].spines[\"right\"].set_visible(False)\n",
    "    plt.subplots_adjust(wspace=.04, hspace=0)\n",
    "    plt.savefig(f'{path_img_dest}images before gifs/iter {i:05d}.jpeg',\n",
    "                bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close(fig)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, LR):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every X epochs\"\"\"\n",
    "    #LR = LR * (0.1 ** (epoch // 1000))\n",
    "    LR = LR * 0.1 \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = LR\n",
    "    return LR\n",
    "\n",
    "\n",
    "def optimize_melanoma_v1(optimizer_type, parameters, closure, LR, num_iter, show_every, path_img_dest, restart = True, annealing=False, lr_finder_flag=False):\n",
    "    \"\"\"\n",
    "    It comes from optimize_v18 we changed the stop training criterion from 0.0005\n",
    "    # We stop training when loss reaches 0.0005. We saw some examples that looked ok\n",
    "    Runs optimization loop.\n",
    "    Args:\n",
    "        optimizer_type: 'LBFGS' of 'adam'\n",
    "        parameters: list of Tensors to optimize over\n",
    "        closure: function, that returns loss variable\n",
    "        LR: learning rate\n",
    "        num_iter: number of iterations\n",
    "    \"\"\"\n",
    "    total_loss = []\n",
    "    images_generated = []\n",
    "    losses_all = []\n",
    "    if optimizer_type == 'adam':\n",
    "        #print('Starting optimization with ADAM')\n",
    "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "\n",
    "        lr_finder = 1e-7\n",
    "        lrs_finder = []\n",
    "        for j in tqdm(range(num_iter)):\n",
    "            # LR finder\n",
    "            if lr_finder_flag:\n",
    "                if j == 0: print('Finding LR')\n",
    "                lr_finder = lr_finder * 1.2\n",
    "                if lr_finder >= 1e-2: #completed\n",
    "                    return total_loss, images_generated, j_best,\n",
    "                lrs_finder.append(lr_finder)\n",
    "                optimizer = torch.optim.Adam(parameters, lr=lr_finder)\n",
    "\n",
    "            # Init values for best loss selection\n",
    "            if j == 0:\n",
    "                loss_best = 1000\n",
    "                j_best = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss_temp, image_generated_temp, losses = closure()\n",
    "            total_loss.append(total_loss_temp)\n",
    "            losses_all.append(losses)\n",
    "\n",
    "            # Restart if bad initialization\n",
    "            if j == 200 and np.sum(np.diff(total_loss)==0) > 50:\n",
    "                \"\"\"if the network is not learning (bad initialization) Restart\"\"\"\n",
    "                restart = True\n",
    "                return total_loss, images_generated, j_best, restart\n",
    "            else:\n",
    "                restart = False\n",
    "\n",
    "            if total_loss_temp < loss_best:\n",
    "                loss_best = total_loss_temp\n",
    "                iterations_without_improvement = 0\n",
    "                j_best = j\n",
    "\n",
    "            if j % 10 == 0: #150 # the first 1500 iterations are blurry\n",
    "                images_generated.append(image_generated_temp)\n",
    "                #plot_for_gif(image_generated_temp, num_iter, j, path_img_dest)\n",
    "\n",
    "            if annealing == True and iterations_without_improvement == 50: # it was 200\n",
    "                LR = adjust_learning_rate(optimizer, j, LR)\n",
    "                print(f'LR reduced to: {LR:.5f}')\n",
    "            #print(f'total_loss_temp:{total_loss_temp}')\n",
    "            optimizer.step()\n",
    "            iterations_without_improvement += 1\n",
    "            # if iterations_without_improvement == 500:\n",
    "                # print(f'training stopped at it {j} after 500 iterations without improvement')\n",
    "                # break\n",
    "    else:\n",
    "        assert False\n",
    "    return total_loss, images_generated, j_best, restart, losses_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
